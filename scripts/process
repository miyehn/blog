#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import glob
import json
import os
import shutil
tmp = ''
rawData = []
rawLocal = []
content_dir = os.environ['MRBLOG_CONTENT']

#remove old files in posts/
paths = glob.glob(content_dir + '/blogposts/*')
for path in paths:
    os.remove(path)

paths = glob.glob(content_dir + '/drafts/*.md')

for path in paths:
    file = open(path, 'r')
    text = file.read().strip()

    header = text[text.find('---\n')+4:]
    body = header[header.find('---\n')+4:]
    header = header[0:header.find('---\n')]

    # parse body to see if has partially hidden content
    ind = body.find('<!--hide-->')+11
    partial = False
    textOrig = ''
    textAlt = ''
    while ind >= 11:
        partial = True
        textOrig += body[0:ind-11]
        textAlt += body[0:ind-11]
        ind2 = body.find('<!--endhide-->')
        if ind2>=0:
            textAlt += body[ind:ind2]
            body = body[ind2 + 14:]
        else:
            textAlt += body[ind:]
            body = ''
        ind = body.find('<!--hide-->')+11
    
    textOrig += body
    textAlt += body

    # title
    ind = header.find('title:')+6
    if ind<6:
        title = ''
    else:
        title = header[ind:]
    title = title[0:title.find('\n')].strip()
    # tags
    ind = header.find('tags:')+5
    if ind<5:
        tagstr = ''
    else:
        tagstr = header[ind:]
    tagstr = tagstr[0:tagstr.find('\n')].strip()[1:-1]
    tagarr0 = tagstr.split(',')
    tagarr0 = filter(None, tagarr0)
    tagarr = []
    for tag in tagarr0:
        tagarr.append(tag.strip())
    # publicity
    ind = header.find('public:')+7
    if ind<5:
        publicity = 3
    elif header[ind:].strip()[0:4].lower()=='true':
        if partial:
            publicity = 1
        else:
            publicity = 0
    elif header[ind:].strip()[0:6].lower()=='hidden':
        publicity = 2
    else:
        publicity = 3
    # date
    ind = header.find('date:')+5
    if ind<5:
        date = ''
    else:
        date = header[ind:]
    date = date[0:date.find('\n')].strip()

    # jsonify
    # for online summary
    data = {
        'title': title,
        'path': path[len(content_dir) + 7:-3],
        'tags': tagarr,
        'publicity': publicity,
        'date': date
    }
    # for local summary
    dataLocal = {
        'title': title,
        'path': path[len(content_dir) + 7:-3],
        'tags': tagarr,
        'publicity': 0,
        'date': date
    }

    # append to summary texts
    rawLocal.append(dataLocal)
    if publicity < 3:
        rawData.append(data)

    # rewrite file content + alt
    path = content_dir + '/blogposts' + path[len(content_dir) + 7:]
    if publicity==1:
        with open(path[:-3]+'-alt', 'w+') as outfile:
            outfile.write(textAlt.strip())
    if publicity==2:
        with open(path[:-3], 'w+') as outfile:
            outfile.write(textAlt.strip())
    else:
        with open(path[:-3], 'w+') as outfile:
            outfile.write(textOrig.strip())

    file.close()

with open(content_dir + '/blogSummary', 'w+') as outfile:
    json.dump(rawData, outfile, indent=4, ensure_ascii=False)
with open(content_dir + '/localSummary', 'w+') as outfile:
    json.dump(rawLocal, outfile, indent=4, ensure_ascii=False)

print('summary generated')

